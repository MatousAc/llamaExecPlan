[general]
quiet: True
ignoreWarnings: True

[paths]
# paths are relative to the llamaExecPlan dir
model: /models/llama-hf/7b-chat
data: /data/queryPlans.csv
log: /data/logs

[dataFormatter]
# we MUST begin with <s> and a space for the tokenizer to match the
# tokens for inputTemplate below with the ones produced in the full input
delim: ###
inputTemplate: <s> ${delim} Create a query execution plan for an RDBMS for the following query: ${delim} Query: <query> ${delim} Execution Plan: <execPlan>
continuationPrompt: Please continue with step <nextStep> of the execution plan. When you feel that you are done with the execution plan, say "Return Results"
; <s> ### Create a query execution plan for an RDBMS for the following query: ### Query: <query> ### Execution Plan: <execPlan>
; <s> ### Create a query execution plan for an RDBMS for the following query: ### Query: select distinct t.startDate from term t join studentSection ss on t.termID = ss.termID where noAttenceFlag = 'False'; ### Execution Plan:

# determines whether you want to observe inference with random data
# following the above template, or if you want to craft your own prompt
# options: manual|generate
sampleMode: generate
