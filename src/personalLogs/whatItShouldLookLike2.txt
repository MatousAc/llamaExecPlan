<transformers.trainer_utils.EvalPrediction object at 0x7fa962d8d890>
Detokenizing Tokens:
<class 'numpy.ndarray'>
[  0 363 410   0  12   0]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[   0  363   19    0 1231    0]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[  123   363    19  1345     0 23212]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[ 643 2645  410 1252  123    0]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[234 363 410   9  23   9]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[    0   363   410 26783     1     0]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[  0 630 410   0  12   2]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[  2 343  19  20 123   2]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[ 123  363   19 1345    2 2212]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[ 643 2645  410 1252  123    2]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[234 363 420   9  23   2]
Detokenizing Tokens:
<class 'numpy.ndarray'>
[    0   362   410 26783     1     2]
Evaluating with Gooogle Bleu
Predictions:
[[    0   363   410     0    12     0]
 [    0   363    19     0  1231     0]
 [  123   363    19  1345     0 23212]
 [  643  2645   410  1252   123     0]
 [  234   363   410     9    23     9]
 [    0   363   410 26783     1     0]]
['for pro\t', 'for\x10String', 'x for\x10 ра Lav', 'ser during proExx', '� for pro\x06\x14\x06', 'for pro Cot']
References:
[[    0   630   410     0    12     2]
 [    2   343    19    20   123     2]
 [  123   363    19  1345     2  2212]
 [  643  2645   410  1252   123     2]
 [  234   363   420     9    23     2]
 [    0   362   410 26783     1     2]]
[['ated pro\t'], ['y\x10\x11x'], ['x for\x10 раjo'], ['ser during proExx'], ['� forame\x06\x14'], ['ation pro Cot']]
{'google_bleu': 0.4375}
