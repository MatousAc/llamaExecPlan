Loading Data . . .
Splitting data . . .
Results:
DatasetDict({
    train: Dataset({
        features: ['sentence', 'answer', 'count'],
        num_rows: 10655
    })
    test: Dataset({
        features: ['sentence', 'answer', 'count'],
        num_rows: 11
    })
})
{'sentence': 'In 1578 king Stefan Batory created the Crown Tribunal in order to reduce the enormous pressure on the Royal Court.', 'answer': '1578 <sep> king Stefan Batory', 'count': 2}
Looking at Logits
All Logits in one:
logits.shape: torch.Size([8, 121, 32000])
tensor([[[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9314e-01,  1.3545e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.4585e+00,  3.4660e+01,  2.2064e+00,  ...,  3.7965e-01,
          -4.9487e-02,  9.7556e-01],
         [ 1.4087e+00,  3.4406e+01,  2.0887e+00,  ...,  3.2451e-01,
          -9.7896e-02,  9.1010e-01],
         [ 1.3182e+00,  3.4174e+01,  2.0301e+00,  ...,  2.3708e-01,
          -1.7711e-01,  8.1875e-01]],

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9314e-01,  1.3545e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.4048e+00,  3.2715e+01,  2.0102e+00,  ..., -3.8647e-01,
          -4.6938e-01,  7.5752e-01],
         [ 1.3959e+00,  3.2648e+01,  1.9616e+00,  ..., -3.9725e-01,
          -4.5904e-01,  7.8129e-01],
         [ 1.4229e+00,  3.2542e+01,  1.9048e+00,  ..., -3.7496e-01,
          -4.0411e-01,  8.0330e-01]],

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9314e-01,  1.3545e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.2615e+00,  3.4789e+01,  3.4038e+00,  ...,  6.2667e-01,
           2.4046e-01,  9.3056e-01],
         [ 1.1904e+00,  3.4804e+01,  3.5155e+00,  ...,  5.7866e-01,
           2.5009e-01,  9.1628e-01],
         [ 1.0808e+00,  3.4624e+01,  3.5891e+00,  ...,  5.0927e-01,
           2.1467e-01,  8.7119e-01]],

        ...,

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9314e-01,  1.3545e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.4694e+00,  3.5469e+01,  1.9431e+00,  ..., -1.0611e+00,
          -1.1457e+00, -1.4426e-01],
         [ 1.3530e+00,  3.5175e+01,  1.9720e+00,  ..., -1.1175e+00,
          -1.1905e+00, -1.8406e-01],
         [ 1.1959e+00,  3.4751e+01,  1.9899e+00,  ..., -1.1855e+00,
          -1.2464e+00, -2.3965e-01]],

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9314e-01,  1.3545e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.3537e+00,  3.5492e+01,  2.3589e+00,  ..., -6.3333e-02,
          -5.3852e-01,  4.4983e-01],
         [ 1.4584e+00,  3.5651e+01,  2.3205e+00,  ...,  2.0156e-03,
          -4.1235e-01,  5.4895e-01],
         [ 1.4744e+00,  3.5665e+01,  2.2795e+00,  ...,  6.7158e-03,
          -3.2079e-01,  5.8169e-01]],

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9314e-01,  1.3545e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.0423e+00,  3.6714e+01,  4.3302e+00,  ..., -4.6229e-01,
          -6.5987e-03,  5.6962e-01],
         [ 9.8645e-01,  3.6536e+01,  4.3090e+00,  ..., -4.9875e-01,
          -7.2344e-02,  5.0595e-01],
         [ 9.6280e-01,  3.6472e+01,  4.3425e+00,  ..., -4.8846e-01,
          -8.8720e-02,  4.8246e-01]]], device='cuda:0')
Looking at Lables
All Labels in one:
labels.shape: torch.Size([8, 121])
tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100, 10545,  6932, 10557,   529,
         19570, 29958,  2860,   980,  5334,   346,  8052,   278, 12060,   310,
           278, 10545, 13378,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  6932, 17700,  7646,  1582,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  2921, 29899,  2577,
          2153,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100, 29871, 29946, 29946,   529, 19570, 29958,
         29871, 29929, 29900, 29892, 29900, 29900, 29900,   529, 19570, 29958,
          4007, 21558,  2529,  9854,   448,   379, 30069, 23600,  2993,   316,
          3681],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,   399,  5989,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  4644, 13397,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,   751,  2559,   666, 13544,  6163,   529, 19570, 29958, 12469,
           432,  2232,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 29871, 29941,
         29892, 29900, 29900, 29900,   529, 19570, 29958, 29871, 29906, 29946,
         29900,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100]], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100, 10545,  6932, 10557,   529,
        19570, 29958,  2860,   980,  5334,   346,  8052,   278, 12060,   310,
          278, 10545, 13378,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  6932, 17700,  7646,  1582,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  2921, 29899,  2577,
         2153,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100, 29871, 29946, 29946,   529, 19570, 29958,
        29871, 29929, 29900, 29892, 29900, 29900, 29900,   529, 19570, 29958,
         4007, 21558,  2529,  9854,   448,   379, 30069, 23600,  2993,   316,
         3681], device='cuda:0')
label.shape: torch.Size([121])
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100,  399, 5989, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  4644, 13397,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,   751,  2559,   666, 13544,  6163,   529, 19570, 29958, 12469,
          432,  2232,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
label.shape: torch.Size([121])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 29871, 29941,
        29892, 29900, 29900, 29900,   529, 19570, 29958, 29871, 29906, 29946,
        29900,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100], device='cuda:0')
Looking at Logits AGAIN
All Logits in one:
logits.shape: torch.Size([8, 121])
tensor([[23196, 13383,    13,    13,   278,  1397,   346, 29892,  1370,  1370,
           310,   278, 10545, 13378, 29892, 29871, 29871, 29896, 29929, 29941,
         29953, 29892,   278, 13230,   768,  5638,   471,  3707,  2388,   287,
           491,   278, 13772, 21260,   423, 29897, 29879, 20123,   310,   471,
         10545,  6254,   284,   309,   392,   313,   443,   964,   278, 10545,
         26474,   287, 13772, 21260,   423,   304,   278,   716,   784,  6932,
         10557, 29889, 29909, 18961, 29650,   744, 28732, 29892,   784,  8542,
         29889, 24366, 24366,    13,   894,  9303,  1309, 29879, 29901,  1147,
         29892,   322,  4959,  2129, 29901, 29871,  6932, 10557, 29892,  1182,
         29958, 10545,   980,  5334,   346,  8052,   278, 12060,   310,   278,
         10545, 13378,   297,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1],
        [23196, 13383,    13,    13, 22569,   310,   263,   310,   278, 29871,
         17700,  7646,  1582, 29892,   263, 29871, 29871, 29941, 29892, 29900,
         29900, 29900, 29899, 26763, 26203, 29946, 29892, 29947, 29900, 29900,
          2383, 29897, 26203,   446, 26203,   393,   674, 16116,   278,  4655,
          4272,   373,   278, 19948, 17700,   310, 26160,   304, 26160, 29889,
         24366, 24366,    13,   894,  8984,  1309, 29879, 29901,  1147, 29892,
           322,  1147,  2129, 29901, 29871, 17700,  7646,  1582, 29892,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1],
        [23196, 13383,    13,    13,   310,   278,  6460,   411,   278, 29882,
         12742,  4193, 29892,   263, 17700, 30010, 29873,  6068,   304,   679,
           670,  6651,  3769,  2745,   577,   540,  8459,   263,  5492,   278,
          4509,   310, 14297,   310,   278,  2318,   265,  8120,  2153, 29889,
           263,  2318, 29871, 29915, 29929, 29929, 29900, 29879, 21464, 21464,
          2318, 29889,   310,  3654, 29892,   360, 12182, 29892,   322, 18776,
           402, 29892,   322,   635,  1938, 29872, 29892,   322,  8168,  1171,
          8508, 29889, 23196, 24366,    13,  1724,  9303,  1309, 29879, 29901,
          1147, 29892,   322, 21702,  2129, 29901, 29871, 29899,  2577,  2153,
         29892,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1],
        [23196, 13383,    13,    13, 18020,   338,  9045, 14703,  5786,  5786,
           313,  7513,  3303,   310,   476,    13,   967,  1014,   332,  5824,
            13,  4944,   491,   278,   317, 21558,  8042,  9854, 29899,   379,
         30069, 23600,  2993,   316,  3681,   313,  3301, 29899,  3954,   467,
           263,   970, 13457,  1788, 29889,   338,   417,   952, 29871,  1135,
         29871, 29929, 29900, 29892, 29900, 29900, 29900,  2305, 29889, 18271,
         29871,   654,   414, 29892,   302, 13925, 29892,   322, 19185,  4097,
           467,   322, 29871, 29946, 29900, 29418,   277,  1338,   322, 24366,
         24366,    13,   894,  9303,  1309, 29879, 29901,  1147, 29892,   322,
          3618,  2129, 29901, 29871, 29896, 29946, 29418,  1182, 29958, 29418,
         29929, 29900, 29892, 29900, 29900, 29900,   529, 19570, 29958, 29871,
         21558,  2529,  9854,   448,   379, 30069, 23600,  2993,   316,  3681,
           529],
        [23196, 13383,    13,    13, 29871, 29871, 29896, 29900, 29892, 29871,
         29906, 29900, 29906, 29929, 29892,   278, 20781,   393,   471,  1063,
           670,  3769,   304,   376,  3235, 29950,   304,   399,  5989, 29889,
           322,   393,  9326,   278,  3769,   310,   278,  4696,  3905,  1537,
         24791, 29871, 29941, 13460,  6046,  1196, 29889,  4104,  2285, 19256,
         19906,   297, 23196, 24366,    13,   894,  9303,  1309, 29879, 29901,
          1147, 29892,   322,  3618,  2129, 29901,  3122,  5989, 29892,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1],
        [23196, 13383,    13,    13,   716,  1353,   310,  2305, 10916,  2305,
          2879,   892,   278, 29871,  3160, 29871,  5134,  1063,  1063,  2356,
           515,   278,  2106,  4275, 29889,  3704, 29901,   880, 14004, 29892,
         14985,   514,   347, 23868,  1358, 29892,   322, 11032,   360,  6482,
           719, 29889,  4249,   599,   599,   515,  4644, 13397, 29889,    13,
         24366,    13,   382,  9303,  1309, 29879, 29901,  1147, 29892,   322,
          7014,  2129, 29901, 29871, 13397, 29892,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1],
        [23196, 13383,    13,    13,  1806, 29911, 29945,    13,   263,   314,
           681,   363,   967,   432,  2232, 29889,   278,   278,   537,   304,
           278,  3088,  4412, 29889,   278,   263,   916, 12180,   310,   278,
          3088,  3496, 29892,   338,  1549,   278,   379,  2559,   666, 13544,
          6163, 29892,   278, 29871, 29880,  3536,  4089, 19722, 16230,   263,
           660, 29984, 16230, 29908,   607,   338,   756,   263, 12469, 12469,
         29880,  1600,   384, 29889, 12469, 29889, 24366, 24366,    13,   894,
          9303,  1309, 29879, 29901,  1147, 29892,   322,  3618,  2129, 29901,
           334,  2559,   666, 13544,  6163, 29892,  1182, 29958,   306,   529,
          2232,   529,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1],
        [23196, 13383,    13,    13, 22569,  3926,  1556, 12239, 10555, 12886,
           310,   297,   402,  1099,  2766, 29889,   988,   278,   501, 29889,
         23196, 29889,  8811,   304,  9621,  2129,   515,   278, 29896, 29900,
         29900, 29900, 29900,   350, 29899, 29906, 29929, 18523,  2596,   304,
           263, 29896, 29900, 29900, 29892, 12628,   310,   285, 29899, 29906,
         29955, 29879,  2596, 29889,   278, 20458,   344, 13585,   292,   358,
           310,  5546, 29889, 29879,  3271, 24191, 29889, 10223,   362,   363,
           278, 20458, 29899,  7052, 28425, 29889, 29871, 29871, 29896, 29929,
         29946, 29945, 29889,    13, 24366,    13,   894,  9303,   688, 29879,
         29901,  1147, 29892,   322, 22001,  2129, 29901, 29871, 29896, 29892,
         29900, 29900, 29900,   350,  1182, 29958,   350, 29906, 29946, 29900,
           529,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1]], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13,   278,  1397,   346, 29892,  1370,  1370,
          310,   278, 10545, 13378, 29892, 29871, 29871, 29896, 29929, 29941,
        29953, 29892,   278, 13230,   768,  5638,   471,  3707,  2388,   287,
          491,   278, 13772, 21260,   423, 29897, 29879, 20123,   310,   471,
        10545,  6254,   284,   309,   392,   313,   443,   964,   278, 10545,
        26474,   287, 13772, 21260,   423,   304,   278,   716,   784,  6932,
        10557, 29889, 29909, 18961, 29650,   744, 28732, 29892,   784,  8542,
        29889, 24366, 24366,    13,   894,  9303,  1309, 29879, 29901,  1147,
        29892,   322,  4959,  2129, 29901, 29871,  6932, 10557, 29892,  1182,
        29958, 10545,   980,  5334,   346,  8052,   278, 12060,   310,   278,
        10545, 13378,   297,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13, 22569,   310,   263,   310,   278, 29871,
        17700,  7646,  1582, 29892,   263, 29871, 29871, 29941, 29892, 29900,
        29900, 29900, 29899, 26763, 26203, 29946, 29892, 29947, 29900, 29900,
         2383, 29897, 26203,   446, 26203,   393,   674, 16116,   278,  4655,
         4272,   373,   278, 19948, 17700,   310, 26160,   304, 26160, 29889,
        24366, 24366,    13,   894,  8984,  1309, 29879, 29901,  1147, 29892,
          322,  1147,  2129, 29901, 29871, 17700,  7646,  1582, 29892,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13,   310,   278,  6460,   411,   278, 29882,
        12742,  4193, 29892,   263, 17700, 30010, 29873,  6068,   304,   679,
          670,  6651,  3769,  2745,   577,   540,  8459,   263,  5492,   278,
         4509,   310, 14297,   310,   278,  2318,   265,  8120,  2153, 29889,
          263,  2318, 29871, 29915, 29929, 29929, 29900, 29879, 21464, 21464,
         2318, 29889,   310,  3654, 29892,   360, 12182, 29892,   322, 18776,
          402, 29892,   322,   635,  1938, 29872, 29892,   322,  8168,  1171,
         8508, 29889, 23196, 24366,    13,  1724,  9303,  1309, 29879, 29901,
         1147, 29892,   322, 21702,  2129, 29901, 29871, 29899,  2577,  2153,
        29892,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13, 18020,   338,  9045, 14703,  5786,  5786,
          313,  7513,  3303,   310,   476,    13,   967,  1014,   332,  5824,
           13,  4944,   491,   278,   317, 21558,  8042,  9854, 29899,   379,
        30069, 23600,  2993,   316,  3681,   313,  3301, 29899,  3954,   467,
          263,   970, 13457,  1788, 29889,   338,   417,   952, 29871,  1135,
        29871, 29929, 29900, 29892, 29900, 29900, 29900,  2305, 29889, 18271,
        29871,   654,   414, 29892,   302, 13925, 29892,   322, 19185,  4097,
          467,   322, 29871, 29946, 29900, 29418,   277,  1338,   322, 24366,
        24366,    13,   894,  9303,  1309, 29879, 29901,  1147, 29892,   322,
         3618,  2129, 29901, 29871, 29896, 29946, 29418,  1182, 29958, 29418,
        29929, 29900, 29892, 29900, 29900, 29900,   529, 19570, 29958, 29871,
        21558,  2529,  9854,   448,   379, 30069, 23600,  2993,   316,  3681,
          529], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13, 29871, 29871, 29896, 29900, 29892, 29871,
        29906, 29900, 29906, 29929, 29892,   278, 20781,   393,   471,  1063,
          670,  3769,   304,   376,  3235, 29950,   304,   399,  5989, 29889,
          322,   393,  9326,   278,  3769,   310,   278,  4696,  3905,  1537,
        24791, 29871, 29941, 13460,  6046,  1196, 29889,  4104,  2285, 19256,
        19906,   297, 23196, 24366,    13,   894,  9303,  1309, 29879, 29901,
         1147, 29892,   322,  3618,  2129, 29901,  3122,  5989, 29892,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13,   716,  1353,   310,  2305, 10916,  2305,
         2879,   892,   278, 29871,  3160, 29871,  5134,  1063,  1063,  2356,
          515,   278,  2106,  4275, 29889,  3704, 29901,   880, 14004, 29892,
        14985,   514,   347, 23868,  1358, 29892,   322, 11032,   360,  6482,
          719, 29889,  4249,   599,   599,   515,  4644, 13397, 29889,    13,
        24366,    13,   382,  9303,  1309, 29879, 29901,  1147, 29892,   322,
         7014,  2129, 29901, 29871, 13397, 29892,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13,  1806, 29911, 29945,    13,   263,   314,
          681,   363,   967,   432,  2232, 29889,   278,   278,   537,   304,
          278,  3088,  4412, 29889,   278,   263,   916, 12180,   310,   278,
         3088,  3496, 29892,   338,  1549,   278,   379,  2559,   666, 13544,
         6163, 29892,   278, 29871, 29880,  3536,  4089, 19722, 16230,   263,
          660, 29984, 16230, 29908,   607,   338,   756,   263, 12469, 12469,
        29880,  1600,   384, 29889, 12469, 29889, 24366, 24366,    13,   894,
         9303,  1309, 29879, 29901,  1147, 29892,   322,  3618,  2129, 29901,
          334,  2559,   666, 13544,  6163, 29892,  1182, 29958,   306,   529,
         2232,   529,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
logit.shape: torch.Size([121])
tensor([23196, 13383,    13,    13, 22569,  3926,  1556, 12239, 10555, 12886,
          310,   297,   402,  1099,  2766, 29889,   988,   278,   501, 29889,
        23196, 29889,  8811,   304,  9621,  2129,   515,   278, 29896, 29900,
        29900, 29900, 29900,   350, 29899, 29906, 29929, 18523,  2596,   304,
          263, 29896, 29900, 29900, 29892, 12628,   310,   285, 29899, 29906,
        29955, 29879,  2596, 29889,   278, 20458,   344, 13585,   292,   358,
          310,  5546, 29889, 29879,  3271, 24191, 29889, 10223,   362,   363,
          278, 20458, 29899,  7052, 28425, 29889, 29871, 29871, 29896, 29929,
        29946, 29945, 29889,    13, 24366,    13,   894,  9303,   688, 29879,
        29901,  1147, 29892,   322, 22001,  2129, 29901, 29871, 29896, 29892,
        29900, 29900, 29900,   350,  1182, 29958,   350, 29906, 29946, 29900,
          529,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1], device='cuda:0')
Done w/ Preprocessing Logits
Looking at Logits
All Logits in one:
logits.shape: torch.Size([3, 69, 32000])
tensor([[[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9313e-01,  1.3544e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [-2.6136e+00,  8.4145e-01,  1.3659e+01,  ...,  1.1399e-01,
           3.1770e-01,  4.8146e-01],
         [-8.0386e+00, -9.9797e+00,  1.0979e+01,  ..., -3.3268e+00,
          -5.7263e+00, -2.6409e+00],
         [-5.5472e+00, -2.1565e+00,  1.1886e+01,  ..., -9.1201e-01,
          -1.7972e+00, -9.2823e-01]],

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9313e-01,  1.3544e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.0877e+00,  3.2528e+01,  2.4704e+00,  ..., -8.7580e-01,
          -8.4895e-01, -7.9072e-02],
         [ 1.2332e+00,  3.3038e+01,  2.4578e+00,  ..., -7.8564e-01,
          -7.2621e-01,  2.0631e-02],
         [ 1.3302e+00,  3.3291e+01,  2.4488e+00,  ..., -7.2691e-01,
          -6.5106e-01,  7.5830e-02]],

        [[-1.4859e+00,  2.4050e+00,  1.2164e+00,  ...,  7.8515e-01,
           2.9313e-01,  1.3544e-01],
         [-8.3112e+00, -5.5205e+00,  1.6696e+00,  ..., -2.5679e+00,
          -5.1724e+00, -1.4139e+00],
         [-1.1342e+01, -9.4539e+00, -1.9422e+00,  ..., -4.9174e+00,
          -7.1400e+00, -7.5160e+00],
         ...,
         [ 1.2051e+00,  3.2512e+01,  2.6121e+00,  ..., -2.4114e-01,
          -6.1681e-01,  3.0188e-01],
         [ 1.2008e+00,  3.2581e+01,  2.5928e+00,  ..., -2.2850e-01,
          -6.1383e-01,  3.0359e-01],
         [ 1.1220e+00,  3.2388e+01,  2.5451e+00,  ..., -2.7043e-01,
          -6.8918e-01,  2.3821e-01]]], device='cuda:0')
Looking at Lables
All Labels in one:
labels.shape: torch.Size([3, 69])
tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  8291,  1090, 29899, 19024,
           653,  2498,   529, 19570, 29958, 15542,   326,  2443,  4983],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100, 26901, 29875,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100, 16078,   529, 19570, 29958, 19525,
           719,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]],
       device='cuda:0')
label.shape: torch.Size([69])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  8291,  1090, 29899, 19024,
          653,  2498,   529, 19570, 29958, 15542,   326,  2443,  4983],
       device='cuda:0')
label.shape: torch.Size([69])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100, 26901, 29875,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
label.shape: torch.Size([69])
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100, 16078,   529, 19570, 29958, 19525,
          719,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
       device='cuda:0')
Looking at Logits AGAIN
All Logits in one:
logits.shape: torch.Size([3, 69])
tensor([[23196, 13383,    13,    13,   278, 29906, 29900, 29896, 29929, 29892,
           278,  2890, 29899, 19024,   653, 29899,   322,   326,  2443,  4983,
          1497,   393,  1346,  1576,  3186,   292, 14451,   297,   278, 17535,
          2318,   310,   278,  4665, 26504,   338,   263,   871,   491, 11423,
         29889, 23196, 24366,    13,  1724,  8984,   688, 29879, 29901,  1147,
           322,   322, 22001,  2129, 29901,  7933, 29892, 29899, 19024,   653,
          2498, 15542,  1182, 29958, 15542,   326,  2443,  4983,   529],
        [23196, 13383,    13,    13,   278,  7786,   970,  3368, 15134,   310,
           278, 20781,   304,  2381,  7251,   515,  5264,   322,  5264,  3654,
           964,   278, 29889,  6826,   304,   736,   701,   297,   263, 29875,
           322,   263,  2446,  2846,  2440, 29889,   322, 16867,   670,  2446,
          3769, 29892, 23196, 24366,    13,   894,  9303,  1309, 29879, 29901,
          1147, 29892,   322,  7014,  2129, 29901, 29871, 29875, 29892,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1],
        [23196, 13383,    13,    13, 29892,   445,   338,   278,   338,   263,
           262,  1189,  1711, 29908,   393,   372,   278,   982,   393,   471,
           278, 10379,  1546,  4628,  1705,   322, 25525,   338,  1475,   278,
          7492,   668, 29897,   322, 17292,   327,   668,   293,  1020,   313,
         24366, 24366,    13,   894,  9303,   688, 29879, 29901,  1147, 29892,
           322, 22001,  2129, 29901, 29871, 29892,  1182, 29958,  8175,   719,
           529,     1,     1,     1,     1,     1,     1,     1,     1]],
       device='cuda:0')
logit.shape: torch.Size([69])
tensor([23196, 13383,    13,    13,   278, 29906, 29900, 29896, 29929, 29892,
          278,  2890, 29899, 19024,   653, 29899,   322,   326,  2443,  4983,
         1497,   393,  1346,  1576,  3186,   292, 14451,   297,   278, 17535,
         2318,   310,   278,  4665, 26504,   338,   263,   871,   491, 11423,
        29889, 23196, 24366,    13,  1724,  8984,   688, 29879, 29901,  1147,
          322,   322, 22001,  2129, 29901,  7933, 29892, 29899, 19024,   653,
         2498, 15542,  1182, 29958, 15542,   326,  2443,  4983,   529],
       device='cuda:0')
logit.shape: torch.Size([69])
tensor([23196, 13383,    13,    13,   278,  7786,   970,  3368, 15134,   310,
          278, 20781,   304,  2381,  7251,   515,  5264,   322,  5264,  3654,
          964,   278, 29889,  6826,   304,   736,   701,   297,   263, 29875,
          322,   263,  2446,  2846,  2440, 29889,   322, 16867,   670,  2446,
         3769, 29892, 23196, 24366,    13,   894,  9303,  1309, 29879, 29901,
         1147, 29892,   322,  7014,  2129, 29901, 29871, 29875, 29892,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1],
       device='cuda:0')
logit.shape: torch.Size([69])
tensor([23196, 13383,    13,    13, 29892,   445,   338,   278,   338,   263,
          262,  1189,  1711, 29908,   393,   372,   278,   982,   393,   471,
          278, 10379,  1546,  4628,  1705,   322, 25525,   338,  1475,   278,
         7492,   668, 29897,   322, 17292,   327,   668,   293,  1020,   313,
        24366, 24366,    13,   894,  9303,   688, 29879, 29901,  1147, 29892,
          322, 22001,  2129, 29901, 29871, 29892,  1182, 29958,  8175,   719,
          529,     1,     1,     1,     1,     1,     1,     1,     1],
       device='cuda:0')
Done w/ Preprocessing Logits
Evaluating with Gooogle Bleu
<transformers.trainer_utils.EvalPrediction object at 0x7f04485c0850>
Everything in Eval Pred:
[[23196 13383    13 ...     1     1     1]
 [23196 13383    13 ...     1     1     1]
 [23196 13383    13 ...     1     1     1]
 ...
 [23196 13383    13 ...  -100  -100  -100]
 [23196 13383    13 ...  -100  -100  -100]
 [23196 13383    13 ...  -100  -100  -100]]
[[-100 -100 -100 ... -100 -100 -100]
 [-100 -100 -100 ... -100 -100 -100]
 [-100 -100 -100 ... -100 -100 -100]
 ...
 [-100 -100 -100 ... -100 -100 -100]
 [-100 -100 -100 ... -100 -100 -100]
 [-100 -100 -100 ... -100 -100 -100]]
<transformers.trainer_utils.EvalPrediction object at 0x7f04485c0850>
Predictions:
[[23196 13383    13 ...     1     1     1]
 [23196 13383    13 ...     1     1     1]
 [23196 13383    13 ...     1     1     1]
 ...
 [23196 13383    13 ...  -100  -100  -100]
 [23196 13383    13 ...  -100  -100  -100]
 [23196 13383    13 ...  -100  -100  -100]]
